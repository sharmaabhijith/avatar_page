<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Framework to test adversarial patches in CARLA and in the real world">
  <meta property="og:title" content="AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time"/>
  <meta property="og:description" content="Framework to test adversarial patches in CARLA and in the real world"/>
  <meta property="og:url" content="https://sharmaabhijith.github.io/avatar_webpage/"/>
  <meta property="og:image" content="static/image/avatar_block_diagram.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time">
  <meta name="twitter:description" content="Framework to test adversarial patches in CARLA and in the real world">
  <meta name="twitter:image" content="static/image/avatar_block_diagram.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="autonomous driving, vehicle safety, adversarial testing, object detection">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sharmaabhijith.github.io" target="_blank">Abhijith Sharma</a><sup>*,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://space.uwo.ca/people/our-members/narayan-apurva/index.html" target="_blank">Apurva Narayan</a><sup>†,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://uwaterloo.ca/automation-intelligent-systems-group/profiles/nasser-lashgarian-azad" target="_blank">Nasser Azad</a><sup>†,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://uwaterloo.ca/electrical-computer-engineering/profile/sfischme" target="_blank">Sebastian Fischmeister</a><sup>†,1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/stefan-marksteiner-332a4184?originalSubdomain=at" target="_blank">Stefan Marksteiner</a><sup>3</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Waterloo,</span>
              <span class="author-block"><sup>2</sup>Western University,</span>
              <span class="author-block"><sup>3</sup>AVL, Graz Austria</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Main Author, <sup>†</sup>Indicates Equal Advising</small></span>
              <span class="eql-cntrb"><small></small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.172165647.71183157/v2" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10646575/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>IEEE TIV</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://sharmaabhijith.github.io/CARLA_Town10_Dataset/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-database"></i>
                    </span>
                    <span>CARLA Town 10 Dataset</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://sharmaabhijith.github.io/avatar_experiment_setup/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-project-diagram"></i>
                    </span>
                    <span>Workflow Setup</span>
                  </a>
                </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
</section>


<!-- Subject Driven Video Generation carousel -->
<section class="hero teaser">
  <div class="hero-body">
          <video 
            id="header-video1" 
            poster="" 
            style="transform: scale(0.7); transform-origin: top center;"
            autoplay 
            muted 
            loop 
            playsinline 
            controls>
            <source src="static/videos/real_world_demo.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <h2 class="subtitle has-text-centered" style="transform: scale(0.9); margin-top: -100px; margin-bottom: 0;">
            The video shows physical real-world testing with the adversarial patch. On the left, the patch is validated on a treadmill-based test-bed with a toy car, and on the right, the patch is applied to a real car moving in an outdoor environment.
          </h2>
  </div>
</section>
<!-- End Subject Driven Video Generation carousel -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Autonomy in vehicles is achieved using AI for
            control and perception tasks. The visual inputs from camera
            forms the foundation for subsequent control that follows. Existing
            works have shown adversarial vulnerabilities during AI based
            visual tasks. One major threat is adversarial patches, which can
            impact decision making in autonomous vehicles (AVs). Current
            evaluation methods often utilize static datasets with unrealistic
            patch placements. This paper proposes a novel framework,
            AVATAR, to standardize adversarial patch testing and analysis.
            AVATAR creates a simulation environment, where the patch is
            integrated with actors in the scene to enhance realism during
            testing. The vehicle’s behaviour is captured as a time-series
            trace for post-simulation quantitative analysis. Furthermore, we
            introduce an Adversarial Trace Classifier (ATC) that analyzes
            these traces to predict the potential presence of adversarial
            patches. The aim is to detect vulnerabilities in object detection
            algorithms for the design of robust perception system for AVs.
            Hence, AVATAR will pave the way for safer deployment of
            autonomous vehicles in real-world.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <center>
          <h2 class="title is-3">📑 Background</h2>
          <img src="static/images/adversarial_test_paradigm.png" alt="Inference Overview" class="center-image" style="transform: scale(0.65); transform-origin: top center; margin-top: 0px;"/>
          </center>
          <div class="level-set has-text-justified" style="margin-top: -170px; margin-bottom: 0;">
            <br>
            <p>
              Figure illustrates the adversarial test paradigm levels. Level 1 applies patches offline to image datasets for object detection, dominating existing research but lacking realism. Level 2 introduces more realistic scenarios by analyzing recorded attacked image frames but lacks real-time validation. Level 3 addresses this gap by enabling real-time adversarial testing within simulation environments, crucial for autonomous vehicle evaluation and often overlooked in existing studies.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

  <!-- Our Contribution -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-narrow" style="writing-mode: vertical-rl; transform: rotate(180deg); text-align: center; margin-right: 30px;">
          <h2 class="title is-3">Our Contribution</h2>
        </div>
        <ul style="list-style-type: none; margin-left: 30px;">
          <li style="margin-bottom: 10px;">
            <strong>🌟 Motivation and Framework Proposal:</strong> Identified the need for Level 3 adversarial patch testing and addressed the absence of existing frameworks by introducing AVATAR, enabling dynamic robustness evaluation for AVs.
          </li>
          <li style="margin-bottom: 10px;">
            <strong>🌟 Dataset and Model Preparation:</strong> Generated the CARLA Town 10HD (CART) dataset and trained object detection models along with adversarial patches specific to Town 10 in CARLA.
          </li>
          <li style="margin-bottom: 10px;">
            <strong>🌟 Simulation and Patch Integration:</strong> Integrated trained adversarial patches into the CARLA environment by modifying asset blueprints and developed the AVATAR framework for real-time dynamic evaluation.
          </li>
          <li style="margin-bottom: 10px;">
            <strong>🌟 User Interface Development:</strong> Designed a GUI for configuring test parameters, setting up experiments, and running simulations in CARLA.
          </li>
          <li style="margin-bottom: 10px;">
            <strong>🌟 Adversarial Trace Detection:</strong> Proposed the Adversarial Trace Classifier (ATC) to predict the presence of adversarial patches post-simulation, ensuring fair and unbiased evaluation
          </li>
        </ul>
      </div>
    </div>
  </section>
  <!-- End Our Contribution -->


<!-- Patch as Material Asset into CARLA -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths" style="margin-top: 10px;">
      <!-- Paper video. -->
      <h2 class="title is-3">🚗 Adversarial Patch in Carla as a Material Asset</h2>
        <div class="columns is-centered has-text-centered" style="margin-top: 40px;">
          <div class="column is-two-fifths">
              <!-- Image embed code here -->
              <img src="static/images/materialblp.png" alt="material blp" style="transform: scale(1);"/>
          </div>
          <div class="column is-three-fifths">
            <!-- Image embed code here -->
            <img src="static/images/vehicle_blp.png" alt="vehicle blp" style="transform: scale(0.9); transform-origin: top center;"/>
          </div>
        </div>
        <div class="level-set has-text-justified" style="margin-top: -50px; margin-bottom: 0;">
          <br>
          <p>
            The adversarial patch can be attached to a CARLA actor (e.g., a moving vehicle) or placed statically in the map. The process begins by converting the trained patch image (.png/.jpeg) into a CARLA asset (.uasset) via Unreal Engine (UE). A material instance is created in UE with high roughness and opacity for optimal visibility. Once converted, the patch can be applied to any CARLA asset. For example, as shown in Figure, the patch is affixed to a vehicle’s board, enabling realistic evaluation of its impact on object detection in dynamic, near-real-world scenarios. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Patch as Material Asset into CARLA -->

<section class="section hero is-small is-light"">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">📝 AVATAR Block Diagram</h2>
          <center>
          <img src="static/images/avatar_block_diagram.jpg" alt="Block Diagram" class="center-image blend-img-background" style="transform: scale(0.9);"/>
          </center>
          <div class="level-set has-text-justified">
            <br>
            <p>
              The AVATAR framework advances Level 3 of adversarial testing by replicating real-world conditions for AV testing. It abstracts the CARLA PythonAPI Client, allowing users to configure parameters and generate a setup file. This file initializes the CARLA environment, loads the object detection model, and applies adversarial patches for experiments. The PyGame window then visualizes the system's behavior under attack in the CARLA simulation. AVATAR enhances adversarial patch testing for autonomous vehicles, ensuring realistic, reproducible, and customizable simulations.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-small"">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div class="content" style="margin-top: -10px;">
          <h2 class="title is-3">🛢️ CART: CARLA Town 10 Dataset</h2>
          <center>
          <img src="static/images/catt.png" alt="Block Diagram" class="center-image blend-img-background" style="transform: scale(0.65); margin-top: -70px; margin-bottom: -50px;"/>
          </center>
          <span class="link-block">
            <a href="https://sharmaabhijith.github.io/CARLA_Town10_Dataset/" target="_blank" class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fa fa-database"></i>
              </span>
              <span>CARLA Town 10 Dataset</span>
            </a>
          </span>
          <div class="level-set has-text-justified" style="margin-top: 10px;">
            <br>
            <p>
              The dataset, generated using CARLA’s Town 10 simulation environment, comprises 4,500 photo-realistic images (4,300 for training, 200 for validation) with a resolution of 1280×720 pixels. It features five key object classes: Person, Vehicle, Motorbike, Traffic Light, and Stop Sign. Captured using autopilot driving in dynamic, moving camera scenarios, the dataset covers diverse lighting conditions (noon, sunset, night) and weather settings (rain, clear, fog). The traffic level includes approximately 40 vehicles and 70 pedestrians, ensuring realistic urban scenes. Annotations are provided in YOLO format. CART is useful for training object detection models and adversarial patches for their use in CARLA or in the real-world.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths" style="margin-top: 20px;">
      <!-- Paper video. -->
      <h2 class="title is-3">🖥️ AVATAR GUI in CARLA</h2>
        <div class="columns is-centered has-text-centered">
          <div class="column is-two-fifths" style="margin-top: 20px;">
            <!-- GUI Image embed code here -->
            <img src="static/images/avatar_gui.png" alt="AVATAR GUI" style="transform: scale(0.87); transform-origin: top center;"/>
          </div>
          <div class="column is-three-fifths" style="margin-top: 20px;">
            <div class="publication-video" style="display: inline-block; transform: scale(0.85); transform-origin: top center;">
              <!-- Youtube embed code here -->
              <iframe src="https://www.youtube.com/embed/g-AqOTro-fY?si=7q17FKDAFmSDrECI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div>
        <div class="level-set has-text-justified" style="margin-top: -70px; margin-bottom: 0;">
          <br>
          <p>
            Tkinter-based GUI featuring four components: CARLA Server Configuration (connects the server, sets seed, mode, and FPS), CARLA World Setting (configures resolution, town, weather, pedestrians, and vehicles), CARLA Actor Setting (sets car model, agent type/behavior, and detection model), and Adversarial Attack Setting (chooses attack type, magnitude, and patch placement on vehicles or billboards). 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->

<!-- Adversarial trace Classifier Results -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <!-- Paper video. -->
        <div class="columns is-centered has-text-centered" style="margin-bottom: 30px; margin-top: 10px;">
          <h2 class="title is-3">⚙️ Adversarial Trace Classifier</h2>
        </div>
        <div class="columns is-centered has-text-centered" style="margin-bottom: -150px;">
          <div class="column is-three-fifths">
              <!-- Image embed code here -->
              <img src="static/images/atc.jpg" alt="atc" style="transform: scale(0.85); transform-origin: top center;"/>
              <img src="static/images/kde_plot.png" alt="atc" style="transform: scale(0.5); transform-origin: top center; margin-top: -70px; margin-bottom: 0;"/>
          </div>
          <div class="column is-two-fifths">
            <!-- Image embed code here -->
            <img src="static/images/results_trace.jpg" alt="result" style="transform: scale(1); transform-origin: top center;"/>
          </div>
        </div>
        <div>
          <ul style="list-style-type: disc; margin-left: 30px;">
            <li style="margin-bottom: 10px;">Simulations were conducted to evaluate YOLO's confidence scores for detecting vehicles under normal and adversarial conditions.</li>
            <li style="margin-bottom: 10px;">Normal conditions showed consistent confidence scores (&gt;85%) across diverse weather and lighting scenarios, indicating model robustness.</li>
            <li style="margin-bottom: 10px;">Adversarial patches caused significant confidence drops and higher variance, especially under optimal lighting (clear noon).</li>
            <li style="margin-bottom: 10px;">Adversarial patch effectiveness reduced in poor visibility scenarios like rain, dust storms, and nighttime conditions.</li>
            <li style="margin-bottom: 10px;">Statistical analysis included 100 traces: 40 nominal and 60 adversarial, with random vehicle starting points.</li>
            <li style="margin-bottom: 10px;">Kernel Density Estimation (KDE) effectively distinguished nominal (tight cluster) and anomalous traces (spread peaks).</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Adversarial trace Classifier Results -->


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-centered has-text-centered" style="margin-bottom: 20px;">
      <!-- Paper video. -->
      <h2 class="title is-3">🎥 Video Presentation</h2>
      <div class="columns is-centered has-text-centered" style="margin-top: 10px;">
        <div class="column is-four-fifths">

          <div class="publication-video" style="display: inline-block; transform: scale(0.8); transform-origin: top center;  margin-bottom: -80px;">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/w9M6zNpd9Es?si=XcHGbTthqdhHrX-4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">📚 BibTeX</h2>
    <pre><code>@article{sharma2024avatar,
      title={AVATAR: Autonomous Vehicle Assessment through Testing of Adversarial Patches in Real-time},
      author={Sharma, Abhijith and Narayan, Apurva and Azad, Nasser Lashgarian and Fischmeister, Sebastian and Marksteiner, Stefan},
      journal={IEEE Transactions on Intelligent Vehicles},
      year={2024},
      publisher={IEEE}
    }
</code></pre>
  </div>
</section>
<!-- End BibTex citation -->

<!--Acknowledgements -->
<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">🙏 Acknowledgements</h2>
    We extend our gratitude to the members of the <a href="https://uwaterloo.ca/embedded-software-group/" target="_blank">Real-time Embedded Software Group</a> @UWaterloo for their invaluable insights, critical brainstorming sessions, and innovative ideas that greatly contributed to this work.
  </div>
</section>
<!--End Acknowledgements -->
  
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
